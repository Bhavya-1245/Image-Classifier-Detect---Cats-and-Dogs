{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavya-1245/Image-Classifier-Detect---Cats-and-Dogs/blob/main/Object_Detection_Web_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# --- 1. LOAD PRE-TRAINED OBJECT DETECTION MODEL ---\n",
        "# We are NOT using our trained classifier. We are loading a\n",
        "# powerful, pre-trained detection model from TensorFlow Hub.\n",
        "# This model (Faster R-CNN) is more accurate but slower than MobileNetV2.\n",
        "print(\"Loading pre-trained object detection model (This may take longer)...\")\n",
        "model_url = \"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\"\n",
        "detector = hub.load(model_url)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "# COCO dataset labels (what this model was trained on)\n",
        "# We only care about 'cat' (ID 17) and 'dog' (ID 18)\n",
        "COCO_LABELS = {\n",
        "    17: \"Cat\",\n",
        "    18: \"Dog\"\n",
        "}\n",
        "\n",
        "# --- 2. DEFINE THE DETECTION FUNCTION ---\n",
        "\n",
        "def detect_objects(image_pil):\n",
        "    \"\"\"\n",
        "    Takes a PIL image, runs detection, and returns the image\n",
        "    with bounding boxes drawn on it.\n",
        "    \"\"\"\n",
        "    if image_pil is None:\n",
        "        return None\n",
        "\n",
        "    # Convert PIL Image to NumPy array\n",
        "    image_np = np.array(image_pil)\n",
        "\n",
        "    # Convert to a tensor\n",
        "    # Add a batch dimension: [height, width, 3] -> [1, height, width, 3]\n",
        "    image_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
        "\n",
        "    # The model expects uint8 tensor\n",
        "    image_tensor = tf.image.convert_image_dtype(image_tensor, tf.uint8)\n",
        "\n",
        "    # --- Run Detection ---\n",
        "    results = detector(image_tensor)\n",
        "\n",
        "    # The output is a dictionary. We take the items from the first (and only) image.\n",
        "    result = {key: value.numpy()[0] for key, value in results.items()}\n",
        "\n",
        "    # Get image dimensions\n",
        "    im_width, im_height = image_pil.size\n",
        "\n",
        "    # Prepare to draw on the image\n",
        "    draw = ImageDraw.Draw(image_pil)\n",
        "\n",
        "    # Try to load a font (optional, but looks good)\n",
        "    try:\n",
        "        font = ImageFont.load_default(size=16)\n",
        "    except IOError:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    # Loop over all detections\n",
        "    for i in range(len(result[\"detection_scores\"])):\n",
        "        score = result[\"detection_scores\"][i]\n",
        "        class_id = int(result[\"detection_classes\"][i])\n",
        "        box = result[\"detection_boxes\"][i]\n",
        "\n",
        "        # --- Filter for Cats and Dogs with > 50% confidence ---\n",
        "        if score > 0.5 and class_id in COCO_LABELS:\n",
        "            label = COCO_LABELS[class_id]\n",
        "\n",
        "            # Get box coordinates in pixels\n",
        "            # The model returns normalized coordinates (0.0 to 1.0)\n",
        "            ymin, xmin, ymax, xmax = box\n",
        "            left = xmin * im_width\n",
        "            right = xmax * im_width\n",
        "            top = ymin * im_height\n",
        "            bottom = ymax * im_height\n",
        "\n",
        "            # --- Draw the Box and Label ---\n",
        "            color = 'red' if label == 'Dog' else 'lime'\n",
        "\n",
        "            # Draw rectangle\n",
        "            draw.rectangle([(left, top), (right, bottom)], outline=color, width=3)\n",
        "\n",
        "            # Draw label background\n",
        "            text = f\"{label}: {int(score * 100)}%\"\n",
        "            text_bbox = draw.textbbox((left, top), text, font=font)\n",
        "            draw.rectangle(text_bbox, fill=color)\n",
        "\n",
        "            # Draw text\n",
        "            draw.text((left, top), text, fill='black', font=font)\n",
        "\n",
        "    return image_pil\n",
        "\n",
        "# --- 3. CREATE THE GRADIO WEB APP ---\n",
        "\n",
        "print(\"Starting Gradio app... Access it at http://127.0.0.1:7860\")\n",
        "\n",
        "# Create the Gradio interface\n",
        "app = gr.Interface(\n",
        "    fn=detect_objects,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload an Image\"),\n",
        "    outputs=gr.Image(type=\"pil\", label=\"Detected Objects\"),\n",
        "    title=\"Project: Cat AND Dog Detector\",\n",
        "    description=\"This app uses a pre-trained SSD MobileNetV2 model from TensorFlow Hub to find cats and dogs in an image and draw boxes around them.\"\n",
        ")\n",
        "\n",
        "# Launch the app!\n",
        "app.launch()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained object detection model (This may take longer)...\n",
            "Model loaded.\n",
            "Starting Gradio app... Access it at http://127.0.0.1:7860\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://458c62f367973421d8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://458c62f367973421d8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "CjJeTMBeEiD7",
        "outputId": "d9ab8aa8-d657-4343-c015-b9f7c409cb8e"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}